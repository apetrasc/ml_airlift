{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315,)\n",
      "torch.Size([315, 2, 2500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2477373/3827091546.py:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.854793645773906\n",
      "re void: 0.06922718707088009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3478], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "torch.Size([1, 16, 500])\n",
      "torch.Size([1, 16, 500])\n",
      "(2, 2500)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m vx\u001b[39m=\u001b[39mvx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=170'>171</a>\u001b[0m vy\u001b[39m=\u001b[39mvy\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m vo\u001b[39m=\u001b[39mmodel(vx)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=172'>173</a>\u001b[0m vloss\u001b[39m=\u001b[39mcriterion(vo,vy)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=173'>174</a>\u001b[0m vrloss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mvloss\u001b[39m.\u001b[39mitem()\u001b[39m*\u001b[39mvx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(x)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    177\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    178\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    181\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    185\u001b[0m     bn_training,\n\u001b[1;32m    186\u001b[0m     exponential_average_factor,\n\u001b[1;32m    187\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    188\u001b[0m )\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2513\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2514\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_env_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/tg_train_two_env_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2env_std\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=16\n",
    "W=2500\n",
    "lr=0.01\n",
    "N=100\n",
    "C=2\n",
    "l1=1e-20\n",
    "l2=1e-7\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.conv1 = nn.Conv1d(1, mid_channel, kernel_size=201,padding=100)\n",
    "        self.bn1 = nn.BatchNorm1d(mid_channel)\n",
    "        self.maxpool1 = nn.MaxPool1d(5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(mid_channel, mid_channel, kernel_size=201, padding=100)\n",
    "        self.bn2 = nn.BatchNorm1d(mid_channel)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(mid_channel*input_channel, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i,:]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.maxpool1(x)\n",
    "            # x = self.ln1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.maxpool1(x)\n",
    "            x = self.relu2(x)\n",
    "            # x = self.ln2(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class GradCAM1d:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_backward_hook(backward_hook))\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        self.model.eval()\n",
    "        input_tensor = input_tensor.to(next(self.model.parameters()).device)\n",
    "        self.model.zero_grad()\n",
    "        out = self.model(input_tensor)\n",
    "        print(out)\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            out = out[0]\n",
    "        target = out.squeeze()\n",
    "        print(target)\n",
    "        if target.ndim > 0:\n",
    "            target = target.sum()\n",
    "        self.model.zero_grad()\n",
    "        target.backward(retain_graph=True)\n",
    "        gradients = self.gradients         # [B, C, L]\n",
    "        print(gradients.shape)\n",
    "        activations = self.activations     # [B, C, L]\n",
    "        print(activations.shape)\n",
    "        weights = gradients.mean(dim=2, keepdim=True)  # [B, C, 1]\n",
    "        grad_cam_map = (weights * activations).sum(dim=1, keepdim=True)  # (B,1,L)\n",
    "        grad_cam_map = torch.relu(grad_cam_map)\n",
    "        grad_cam_map = torch.nn.functional.interpolate(\n",
    "            grad_cam_map, size=input_tensor.shape[2], mode='linear', align_corners=False\n",
    "        )\n",
    "        grad_cam_map = grad_cam_map.squeeze().cpu().numpy()\n",
    "        grad_cam_map = (grad_cam_map - grad_cam_map.min()) / (grad_cam_map.max() - grad_cam_map.min() + 1e-8)\n",
    "        return grad_cam_map\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "print(x_train.shape)\n",
    "# x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(t_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "xgradcam=x[50,:,:]\n",
    "xgradcam=xgradcam.unsqueeze(0)\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "\n",
    "for k in range(10):\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNN(W,C).to(device)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l1*l1n+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "    print(targ.shape)\n",
    "\n",
    "    # corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient solid: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    # print(f're solid: {re}')\n",
    "    # res_list.append(re)\n",
    "    # coefs_list.append(coef)\n",
    "    # corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient void: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    # print(f're void: {re}')\n",
    "    # reg_list.append(re)\n",
    "    # coefg_list.append(coef)\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    # plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(-0.0, 0.05)\n",
    "    # plt.ylim(-0.0, 0.05)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    # plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(0, 0.4)\n",
    "    # plt.ylim(0, 0.4)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ, pred, alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    target_layer = None\n",
    "    if hasattr(model, 'conv3'):\n",
    "        target_layer = model.conv3\n",
    "    elif hasattr(model, 'layer3'):\n",
    "        target_layer = model.layer3\n",
    "    else:\n",
    "        for m in reversed(list(model.modules())):\n",
    "            if isinstance(m, torch.nn.Conv1d):\n",
    "                target_layer = m\n",
    "                break\n",
    "    if target_layer is None:\n",
    "        raise RuntimeError(\"Could not find a suitable layer for Grad-CAM.\")\n",
    "\n",
    "    gradcam_output_dir = os.path.join(odir, \"gradcam\")\n",
    "    gradcam = GradCAM1d(model, target_layer)\n",
    "    grad_cam_map = gradcam(xgradcam)\n",
    "    gradcam.remove_hooks()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    amp=10\n",
    "    ta=np.arange(W)\n",
    "    xgradcam=xgradcam.detach().cpu()\n",
    "    xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    grad_cam_map *= 30\n",
    "    grad_cam_map -= amp\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.plot(ta,grad_cam_map[:], color='red', label='Saliency-Map')\n",
    "    plt.fill_between(ta, grad_cam_map[:],-amp,\n",
    "            color='red',alpha=0.1)\n",
    "    plt.xlabel('Time Axis')\n",
    "    plt.ylabel('Pressure [-]')\n",
    "    plt.ylim(-amp,2*amp)\n",
    "    plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.ylim(-amp,5*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    plt.xlim(0,W)\n",
    "    plt.grid(True)\n",
    "    # plt.xlim(35,40)\n",
    "    plt.tight_layout()\n",
    "    new_save_path = os.path.join(odir, f\"gradcam{k}.png\")\n",
    "    plt.savefig(new_save_path)\n",
    "    plt.close()\n",
    "\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 1. まずデバイスに送る\n",
    "    xgradcam = xgradcam.to(device)\n",
    "\n",
    "    # 2. デバイス移動「後」に勾配追跡をONにする\n",
    "    xgradcam.requires_grad_()\n",
    "\n",
    "    # 3. 予測\n",
    "    output = model(xgradcam)\n",
    "\n",
    "    # 4. 逆伝播（クラス1に注目する場合）\n",
    "    loss = output[0]\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. 勾配を取り出す（.gradプロパティに格納されている）\n",
    "    if xgradcam.grad is not None:\n",
    "        grads = xgradcam.grad.data # ここで [1, 5, 2500] が取得できる\n",
    "        \n",
    "        # --- チャネル別重要度スコアの計算 ---\n",
    "        # abs()をとって時間方向に平均\n",
    "        salimap = grads.abs().squeeze(0)\n",
    "        \n",
    "        # 0~1に正規化（安全のために 1e-8 を足す）\n",
    "        salimap = salimap / (salimap.max() + 1e-8)\n",
    "        \n",
    "        salimap = salimap.cpu().numpy()\n",
    "        salimap = salimap*10\n",
    "        print(salimap.shape)\n",
    "    else:\n",
    "        print(\"勾配が取得できませんでした。requires_gradの位置を確認してください。\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    amp=10\n",
    "    xgradcam=xgradcam.detach().cpu()\n",
    "    xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.plot(ta,salimap[0,:], color='red', label='Saliency-Map')\n",
    "    plt.fill_between(ta, salimap[0,:],0,\n",
    "            color='red',alpha=0.1)\n",
    "    plt.plot(ta,amp+salimap[1,:], color='red', label='Saliency-Map')\n",
    "    plt.fill_between(ta, amp+salimap[1,:],amp,\n",
    "            color='red',alpha=0.1)\n",
    "    # plt.plot(ta,2*amp+salimap[2,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, 2*amp+salimap[2,:],2*amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.plot(ta,3*amp+salimap[3,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, 3*amp+salimap[3,:],3*amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.plot(ta,4*amp+salimap[4,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, 4*amp+salimap[4,:],4*amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    plt.xlabel('Time Axis')\n",
    "    plt.ylabel('Pressure [-]')\n",
    "    plt.ylim(-amp,2*amp)\n",
    "    plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.ylim(-amp,5*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    plt.xlim(0,W)\n",
    "    plt.grid(True)\n",
    "    # plt.xlim(35,40)\n",
    "    plt.tight_layout()\n",
    "    new_save_path = os.path.join(odir, f\"saliency{k}.png\")\n",
    "    plt.savefig(new_save_path)\n",
    "    plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315, 5000)\n",
      "torch.Size([315, 5000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2477373/4007650871.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 2)\n",
      "coefficient solid: 0.02177270765043013\n",
      "re solid: 0.0864326129519261\n",
      "coefficient void: 0.4073011715276601\n",
      "re void: 0.1551480856927843\n",
      "(48, 2)\n",
      "coefficient solid: -0.16876370558618184\n",
      "re solid: 0.1056087647700873\n",
      "coefficient void: 0.420211273843451\n",
      "re void: 0.29851362512419943\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m o\u001b[39m=\u001b[39mmodel(bx)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m loss\u001b[39m=\u001b[39mcriterion(o,by)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m l1n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m l2n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:538\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 538\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/functional.py:3384\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3381\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3383\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(\u001b[39minput\u001b[39m, target)\n\u001b[0;32m-> 3384\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_raw_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/t_train_two_raw_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2raw_std_nn\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=64\n",
    "W=2500\n",
    "lr=0.001\n",
    "N=100\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_length,4096)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096,2)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "\n",
    "for k in range(10):\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=B,shuffle=False)\n",
    "    model=SimpleNN(W*C).to(device)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l1*l1n+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "\n",
    "    corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient solid: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    print(f're solid: {re}')\n",
    "    res_list.append(re)\n",
    "    coefs_list.append(coef)\n",
    "    corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(-0.0, 0.05)\n",
    "    plt.ylim(-0.0, 0.05)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
