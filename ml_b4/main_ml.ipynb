{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 21:51:13,547] A new study created in memory with name: no-name-acaf5f9a-cbbf-4c5c-87c0-841e6958b578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 2, 3000)\n",
      "(483,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3747402/1912012082.py:235: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
      "[W 2026-01-14 21:51:49,593] Trial 0 failed with parameters: {'lr': 1.2394085273648872e-06, 'num_epochs': 96, 'batch_size': 16, 'l2_lambda': 5.935898490593577e-09} because of the following error: IndexError('too many indices for array: array is 1-dimensional, but 2 were indexed').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user01/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3747402/1912012082.py\", line 253, in objective\n",
      "    targ[0,:]=targ[0,:]/10\n",
      "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "[W 2026-01-14 21:51:49,594] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=363'>364</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(reg_list)\u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39mmean(res_list)\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=365'>366</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=366'>367</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=368'>369</a>\u001b[0m best_trial\u001b[39m=\u001b[39mstudy\u001b[39m.\u001b[39mbest_trial\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=369'>370</a>\u001b[0m best_rmse\u001b[39m=\u001b[39mbest_trial\u001b[39m.\u001b[39mvalue \n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     _optimize(\n\u001b[1;32m    491\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    492\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    493\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    494\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    495\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    496\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    497\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    498\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    499\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    500\u001b[0m     )\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         _optimize_sequential(\n\u001b[1;32m     68\u001b[0m             study,\n\u001b[1;32m     69\u001b[0m             func,\n\u001b[1;32m     70\u001b[0m             n_trials,\n\u001b[1;32m     71\u001b[0m             timeout,\n\u001b[1;32m     72\u001b[0m             catch,\n\u001b[1;32m     73\u001b[0m             callbacks,\n\u001b[1;32m     74\u001b[0m             gc_after_trial,\n\u001b[1;32m     75\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     77\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    165\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    206\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=250'>251</a>\u001b[0m pred\u001b[39m=\u001b[39mpred\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=251'>252</a>\u001b[0m targ\u001b[39m=\u001b[39mtarg\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=252'>253</a>\u001b[0m targ[\u001b[39m0\u001b[39m,:]\u001b[39m=\u001b[39mtarg[\u001b[39m0\u001b[39;49m,:]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=253'>254</a>\u001b[0m pred[\u001b[39m0\u001b[39m,:]\u001b[39m=\u001b[39mpred[\u001b[39m0\u001b[39m,:]\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=255'>256</a>\u001b[0m testresult[\u001b[39m0\u001b[39m,:]\u001b[39m=\u001b[39mtarg[\u001b[39m0\u001b[39m,:]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml','r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "dataset_type=\"1d_raw_std\"\n",
    "target_type=\"gas\"\n",
    "x_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_train_{dataset_type}.npy\")\n",
    "t_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_train_{dataset_type}.npy\")\n",
    "x_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "t_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_test_{dataset_type}.npy\")\n",
    "\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/dataset\"\n",
    "odir=os.path.join(bdir,f\"outputs_issei_{dataset_type}_{target_type}\")\n",
    "os.makedirs(odir,exist_ok=True)\n",
    "device=\"cuda:0\"\n",
    "W     = config['hyperparameter']['input_length']\n",
    "H     = config['hyperparameter']['input_height']\n",
    "C     = config['hyperparameter']['input_channel']\n",
    "dropout = config['hyperparameter']['dropout']\n",
    "ksize1 = config['hyperparameter']['ksize1']\n",
    "ksize2 = config['hyperparameter']['ksize2']\n",
    "stride1 = config['hyperparameter']['stride1']\n",
    "stride2 = config['hyperparameter']['stride2']\n",
    "maxpool = config['hyperparameter']['maxpool']\n",
    "SEED = config['hyperparameter']['seed']\n",
    "kfolds = config['hyperparameter']['kfolds']\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # CUDAがある場合\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class SimpleCNNissei(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNNissei, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(4*input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel*4).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,4*self.mid_channel*i:4*self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.input_channel = input_channel\n",
    "#         self.input_length = input_length\n",
    "#         self.mid_channel = mid_channel\n",
    "#         self.models = nn.ModuleList([\n",
    "#             self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "#         ])\n",
    "#         self.fc = nn.Linear(input_channel*mid_channel,2)\n",
    "#         # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "#         # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "#     def _build_sub_network(self, mid_channel):\n",
    "#         return nn.Sequential(\n",
    "#             nn.Conv1d(1, mid_channel, kernel_size=ksize1, stride=stride1),\n",
    "#             nn.BatchNorm1d(mid_channel),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(maxpool),\n",
    "#             nn.Conv1d(mid_channel, mid_channel, kernel_size=ksize2, stride=stride2),\n",
    "#             nn.BatchNorm1d(mid_channel),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(maxpool),\n",
    "#             nn.AdaptiveAvgPool1d(1),\n",
    "#             nn.Dropout(dropout)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, xall):\n",
    "#         bsize = xall.shape[0]\n",
    "#         output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "#         for i in range(self.input_channel):\n",
    "#             x = xall[:,i]\n",
    "#             x = x.unsqueeze(1)\n",
    "#             x = self.models[i](x)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "#         output = self.fc(output)\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "\n",
    "def objective(trial):\n",
    "    curodir=os.path.join(odir,f\"case{trial.number}\")\n",
    "    wdir=os.path.join(curodir,\"weights\")\n",
    "    ldir=os.path.join(curodir,\"logs\")\n",
    "    os.makedirs(curodir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    lr    = trial.suggest_float(\"lr\",1e-6,1e-2,log=True)\n",
    "    N     = trial.suggest_int(\"num_epochs\",30,100)\n",
    "    B     = trial.suggest_categorical(\"batch_size\",[16,32,64])\n",
    "    l2    = trial.suggest_float(\"l2_lambda\",1e-9,1e-3,log=True)\n",
    "    res_list=[]\n",
    "    coefs_list=[]\n",
    "    reg_list=[]\n",
    "    coefg_list=[]\n",
    "    set_seed(SEED)\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=SEED)\n",
    "    dataset=TensorDataset(x,t)\n",
    "    Nttl=len(dataset)\n",
    "    rng=np.random.default_rng()\n",
    "    xt=torch.from_numpy(x_test).float()\n",
    "    tt=torch.from_numpy(t_test).float()\n",
    "    testset=TensorDataset(xt,tt)\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    testsize=len(testset)\n",
    "    best_val_loss_list=[]\n",
    "\n",
    "    for k, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        trasize=len(train_idx)\n",
    "        valsize=len(val_idx)\n",
    "        testresult=np.zeros((4,valsize))\n",
    "        # trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "        trainset=Subset(dataset, train_idx)\n",
    "        valset = Subset(dataset, val_idx)\n",
    "        trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "        valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "        # testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "        model=SimpleCNNissei(W,C).to(device)\n",
    "\n",
    "        # criterion=nn.HuberLoss(delta=delta)\n",
    "        criterion=nn.MSELoss()\n",
    "        optimizer=optim.Adam(params=model.parameters(),lr=lr,weight_decay=l2)\n",
    "        tlosshistory=[]\n",
    "        vlosshistory=[]\n",
    "\n",
    "        for epoch in range(N):\n",
    "            model.train()\n",
    "            rloss=0.0\n",
    "            for bx, by in trainloader:\n",
    "                # start_idx=rng.integers(250)\n",
    "                start_idx=0\n",
    "                bx=bx[:,:,start_idx:start_idx+W]\n",
    "                bx=bx.to(device)\n",
    "                by=by.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                o=model(bx)\n",
    "                loss=criterion(o,by)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                rloss=rloss+loss.item()*bx.size(0)\n",
    "            eloss=rloss/len(trainloader.dataset)\n",
    "            tlosshistory.append(eloss)\n",
    "\n",
    "            model.eval()\n",
    "            vrloss=0.0\n",
    "            with torch.no_grad():\n",
    "                for vx,vy in valloader:\n",
    "                    vx=vx[:,:,:W]\n",
    "                    vx=vx.to(device)\n",
    "                    vy=vy.to(device)\n",
    "                    vo=model(vx)\n",
    "                    vloss=criterion(vo,vy)\n",
    "                    vrloss+=vloss.item()*vx.size(0)\n",
    "            veloss=vrloss/len(valloader.dataset)\n",
    "            vlosshistory.append(veloss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "        plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "        plt.title('Learning Curve (Log Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Log(Loss)')\n",
    "        plt.rcParams[\"font.size\"] = 16\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "        plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "        plt.title('Learning Curve (Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "        model=model.to(device)\n",
    "        model.eval()\n",
    "        pred=[]\n",
    "        targ=[]\n",
    "        with torch.no_grad():\n",
    "            for tx,ty in valloader:\n",
    "                tx=tx[:,:,:W]\n",
    "                tx=tx.to(device)\n",
    "                ty=ty.to(device)\n",
    "                o=model(tx)\n",
    "                pred.append(o.cpu())\n",
    "                targ.append(ty.cpu())\n",
    "        pred=torch.cat(pred,dim=0)\n",
    "        targ=torch.cat(targ,dim=0)\n",
    "\n",
    "        pred=pred.numpy().transpose()\n",
    "        targ=targ.numpy().transpose()\n",
    "        targ[0,:]=targ[0,:]/10\n",
    "        pred[0,:]=pred[0,:]/10\n",
    "\n",
    "        testresult[0,:]=targ[0,:]\n",
    "        testresult[1,:]=pred[0,:]\n",
    "        testresult[2,:]=targ[1,:]\n",
    "        testresult[3,:]=pred[1,:]\n",
    "        np.save(os.path.join(wdir,f'result{k}.npy'),testresult)\n",
    "\n",
    "        corr=np.corrcoef(targ[0,:],pred[0,:])\n",
    "        coef=corr[0,1]\n",
    "        print(f'coefficient solid: {coef}')\n",
    "        re=np.sqrt(np.sum(np.power(targ[0,:]-pred[0,:],2))/targ.shape[1])\n",
    "        print(f're solid: {re}')\n",
    "        res_list.append(re)\n",
    "        coefs_list.append(coef)\n",
    "        corr=np.corrcoef(targ[1,:],pred[1,:])\n",
    "        coef=corr[0,1]\n",
    "        print(f'coefficient void: {coef}')\n",
    "        re=np.sqrt(np.sum(np.power(targ[1,:]-pred[1,:],2))/targ.shape[1])\n",
    "        print(f're void: {re}')\n",
    "        reg_list.append(re)\n",
    "        coefg_list.append(coef)\n",
    "\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ[1,:], pred[1,:], alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.4)\n",
    "        plt.ylim(0, 0.4)\n",
    "        plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "        plt.close()\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ[0,:], pred[0,:], alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.06)\n",
    "        plt.ylim(0, 0.06)\n",
    "        plt.xticks([0,0.02,0.04,0.06])\n",
    "        plt.yticks([0,0.02,0.04,0.06])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    reg_list=np.array(reg_list)\n",
    "    coefg_list=np.array(coefg_list)\n",
    "    res_list=np.array(res_list)\n",
    "    coefs_list=np.array(coefs_list)\n",
    "    print(f\"res:{np.mean(res_list)}\")\n",
    "    print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "    print(f\"reg:{np.mean(reg_list)}\")\n",
    "    print(f\"coefg:{np.mean(coefg_list)}\")\n",
    "    df = pl.DataFrame({\n",
    "        \"RMSE\":reg_list,\n",
    "        \"R2\":coefg_list\n",
    "    })\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    df = pl.concat([\n",
    "        df,\n",
    "        mean,\n",
    "        std\n",
    "    ])\n",
    "    df.write_csv(os.path.join(curodir,\"result_void.csv\"))\n",
    "    df = pl.DataFrame({\n",
    "        \"RMSE\":res_list,\n",
    "        \"R2\":coefs_list\n",
    "    })\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    df = pl.concat([\n",
    "        df,\n",
    "        mean,\n",
    "        std\n",
    "    ])\n",
    "    df.write_csv(os.path.join(curodir,\"result_solid.csv\"))\n",
    "    trial.set_user_attr(\"r2scores\", np.mean(coefs_list))\n",
    "    trial.set_user_attr(\"r2scoreg\", np.mean(coefg_list))\n",
    "    trial.set_user_attr(\"rmseg\", np.mean(reg_list))\n",
    "    trial.set_user_attr(\"rmses\", np.mean(res_list))\n",
    "\n",
    "    config[\"best_hyperparameters\"]={\n",
    "        \"lr\":float(lr),\n",
    "        \"num_epochs\": int(N),\n",
    "        \"batch_size\": int(B),\n",
    "        \"l2_lambda\": float(l2),\n",
    "        \"metrics\": {\n",
    "            \"rmse_void\": float(np.mean(reg_list)),\n",
    "            \"r2_void\":float(np.mean(coefg_list)),\n",
    "            \"rmse_solid\": float(np.mean(res_list)),\n",
    "            \"r2_solid\":float(np.mean(coefs_list))\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(curodir,\"config.yaml\"),\"w\") as f:\n",
    "        yaml.dump(config,f,default_flow_style=False,sort_keys=False)\n",
    "\n",
    "    return np.mean(reg_list)+np.mean(res_list)*10\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_trial=study.best_trial\n",
    "best_rmse=best_trial.value \n",
    "best_params=best_trial.params\n",
    "best_r2_solid = best_trial.user_attrs[\"r2scores\"]\n",
    "best_r2_void = best_trial.user_attrs[\"r2scoreg\"]\n",
    "best_rmse_solid = best_trial.user_attrs[\"rmses\"]\n",
    "best_rmse_void = best_trial.user_attrs[\"rmseg\"]\n",
    "\n",
    "print(f\"Best trial number: {study.best_trial.number}\")\n",
    "\n",
    "config[\"best_hyperparameters\"]={\n",
    "    \"lr\":float(best_params[\"lr\"]),\n",
    "    \"num_epochs\": int(best_params[\"num_epochs\"]),\n",
    "    \"batch_size\": int(best_params[\"batch_size\"]),\n",
    "    \"l2_lambda\": float(best_params[\"l2_lambda\"]),\n",
    "    \"metrics\": {\n",
    "            \"rmse_void\": float(best_rmse_void),\n",
    "            \"r2_void\":float(best_r2_void),\n",
    "            \"rmse_solid\": float(best_rmse_solid),\n",
    "            \"r2_solid\":float(best_r2_solid)\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(odir,\"config.yaml\"),\"w\") as f:\n",
    "    yaml.dump(config,f,default_flow_style=False,sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/Document/yyamaguchi/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2026-01-18 16:19:09,238] A new study created in memory with name: no-name-c2c76e66-0595-4a3a-b301-e8ff36f5595d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 2, 3000)\n",
      "(483,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3949160/4199930222.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8130714932196899\n",
      "re void: 0.055977405646553124\n",
      "coefficient void: 0.8113689876808546\n",
      "re void: 0.05181398813969419\n",
      "coefficient void: 0.8634930142363472\n",
      "re void: 0.04991634599657196\n",
      "coefficient void: 0.8467175263430838\n",
      "re void: 0.0504770198119962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:20:26,754] Trial 0 finished with value: 0.05214832344403024 and parameters: {'lr': 0.0001, 'num_epochs': 50, 'batch_size': 32, 'l2_lambda': 0.5}. Best is trial 0 with value: 0.05214832344403024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8220305994829479\n",
      "re void: 0.05255685762533571\n",
      "reg:0.05214832344403024\n",
      "coefg:0.8313363241925847\n",
      "Epoch ended at 146\n",
      "coefficient void: 0.8368552095996064\n",
      "re void: 0.05260362470715675\n",
      "Epoch ended at 121\n",
      "coefficient void: 0.8066150288126909\n",
      "re void: 0.05246825653232187\n",
      "Epoch ended at 129\n",
      "coefficient void: 0.887468555529851\n",
      "re void: 0.04515210243222866\n",
      "Epoch ended at 73\n",
      "coefficient void: 0.8603678146896657\n",
      "re void: 0.0481133436715839\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:23:25,098] Trial 1 finished with value: 0.049808523261514207 and parameters: {'lr': 0.001, 'num_epochs': 250, 'batch_size': 32, 'l2_lambda': 0.5}. Best is trial 1 with value: 0.049808523261514207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8366772829847821\n",
      "re void: 0.05070528896427985\n",
      "reg:0.049808523261514207\n",
      "coefg:0.8455967783233191\n",
      "coefficient void: 0.7941945636542684\n",
      "re void: 0.058334911486140346\n",
      "coefficient void: 0.7815749314062288\n",
      "re void: 0.05548664090856003\n",
      "coefficient void: 0.8557195848478918\n",
      "re void: 0.05247506338783718\n",
      "coefficient void: 0.8088103166251112\n",
      "re void: 0.05528463468150851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:24:09,641] Trial 2 finished with value: 0.055481126799438674 and parameters: {'lr': 0.001, 'num_epochs': 30, 'batch_size': 64, 'l2_lambda': 0.5}. Best is trial 1 with value: 0.049808523261514207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.7978828640252311\n",
      "re void: 0.05582438353314729\n",
      "reg:0.055481126799438674\n",
      "coefg:0.8076364521117464\n",
      "coefficient void: 0.7936422037749927\n",
      "re void: 0.05832371838487869\n",
      "coefficient void: 0.7847988891293978\n",
      "re void: 0.05510353695341483\n",
      "coefficient void: 0.8620647088191749\n",
      "re void: 0.05073585114480177\n",
      "coefficient void: 0.8148290838724236\n",
      "re void: 0.05459525070755373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:24:59,143] Trial 3 finished with value: 0.05482570736820741 and parameters: {'lr': 0.001, 'num_epochs': 30, 'batch_size': 32, 'l2_lambda': 0.3}. Best is trial 1 with value: 0.049808523261514207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.802275622764771\n",
      "re void: 0.055370179650388034\n",
      "reg:0.05482570736820741\n",
      "coefg:0.811522101672152\n",
      "coefficient void: 0.8395537655300104\n",
      "re void: 0.05215173306806486\n",
      "coefficient void: 0.803468041214411\n",
      "re void: 0.05291989826180218\n",
      "coefficient void: 0.8785059166390157\n",
      "re void: 0.046952450728751365\n",
      "Epoch ended at 102\n",
      "coefficient void: 0.8596138075372446\n",
      "re void: 0.04830149050648306\n",
      "Epoch ended at 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:27:54,201] Trial 4 finished with value: 0.05039174288807402 and parameters: {'lr': 0.0001, 'num_epochs': 130, 'batch_size': 64, 'l2_lambda': 0.1}. Best is trial 1 with value: 0.049808523261514207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8290143782029494\n",
      "re void: 0.051633141875268636\n",
      "reg:0.05039174288807402\n",
      "coefg:0.8420311818247261\n",
      "Epoch ended at 161\n",
      "coefficient void: 0.8324828082631011\n",
      "re void: 0.05309505277867314\n",
      "Epoch ended at 53\n",
      "coefficient void: 0.7847281567145762\n",
      "re void: 0.05493511944883493\n",
      "Epoch ended at 94\n",
      "coefficient void: 0.8646456733169814\n",
      "re void: 0.04968374885814885\n",
      "Epoch ended at 163\n",
      "coefficient void: 0.8756906835724313\n",
      "re void: 0.0459317397649554\n",
      "Epoch ended at 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:30:32,806] Trial 5 finished with value: 0.05133658929396236 and parameters: {'lr': 0.01, 'num_epochs': 210, 'batch_size': 64, 'l2_lambda': 0.3}. Best is trial 1 with value: 0.049808523261514207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8193435709722511\n",
      "re void: 0.05303728561919951\n",
      "reg:0.05133658929396236\n",
      "coefg:0.8353781785678681\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:33:28,405] Trial 6 finished with value: 0.04963169993488552 and parameters: {'lr': 0.01, 'num_epochs': 250, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 170\n",
      "coefficient void: 0.8427515521962285\n",
      "re void: 0.051659803452674596\n",
      "Epoch ended at 105\n",
      "coefficient void: 0.8252268384424941\n",
      "re void: 0.050200134496230175\n",
      "Epoch ended at 72\n",
      "coefficient void: 0.861626475982056\n",
      "re void: 0.05086435812410735\n",
      "Epoch ended at 180\n",
      "coefficient void: 0.8847790290864774\n",
      "re void: 0.04415070255548765\n",
      "Epoch ended at 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:36:23,936] Trial 7 finished with value: 0.04974615458730535 and parameters: {'lr': 0.0001, 'num_epochs': 250, 'batch_size': 64, 'l2_lambda': 0.1}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8270890907902105\n",
      "re void: 0.051855774308026986\n",
      "reg:0.04974615458730535\n",
      "coefg:0.8482945972994933\n",
      "coefficient void: 0.8421157937538291\n",
      "re void: 0.05174284538467005\n",
      "Epoch ended at 102\n",
      "coefficient void: 0.8129860632940688\n",
      "re void: 0.051667585012196614\n",
      "Epoch ended at 93\n",
      "coefficient void: 0.8630674262078107\n",
      "re void: 0.04972771718746394\n",
      "Epoch ended at 79\n",
      "coefficient void: 0.8608640672185777\n",
      "re void: 0.04774318475898445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:39:08,054] Trial 8 finished with value: 0.05050290145739202 and parameters: {'lr': 0.001, 'num_epochs': 150, 'batch_size': 64, 'l2_lambda': 0.1}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8292563521689188\n",
      "re void: 0.0516331749436451\n",
      "reg:0.05050290145739202\n",
      "coefg:0.841657940528641\n",
      "Epoch ended at 109\n",
      "coefficient void: 0.8235754142110017\n",
      "re void: 0.0543862078529938\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.7996217058234742\n",
      "re void: 0.05325369875348346\n",
      "Epoch ended at 67\n",
      "coefficient void: 0.8632116423774187\n",
      "re void: 0.04992186528339282\n",
      "Epoch ended at 148\n",
      "coefficient void: 0.8634036451375567\n",
      "re void: 0.047802513961102\n",
      "Epoch ended at 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:41:46,214] Trial 9 finished with value: 0.051297161632053376 and parameters: {'lr': 0.001, 'num_epochs': 230, 'batch_size': 64, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8324740030107527\n",
      "re void: 0.051121522309294794\n",
      "reg:0.051297161632053376\n",
      "coefg:0.8364572821120408\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:44:42,168] Trial 10 finished with value: 0.04963169993488552 and parameters: {'lr': 0.01, 'num_epochs': 170, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:47:37,670] Trial 11 finished with value: 0.04963169993488552 and parameters: {'lr': 0.01, 'num_epochs': 190, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:50:32,769] Trial 12 finished with value: 0.04963169993488552 and parameters: {'lr': 0.01, 'num_epochs': 150, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:53:30,702] Trial 13 finished with value: 0.04963169993488552 and parameters: {'lr': 1e-05, 'num_epochs': 190, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "coefficient void: 0.8201386615347702\n",
      "re void: 0.054967235031406325\n",
      "coefficient void: 0.8074022666068716\n",
      "re void: 0.05227346977505363\n",
      "coefficient void: 0.8817169943079637\n",
      "re void: 0.04700155641527026\n",
      "coefficient void: 0.8693846296054176\n",
      "re void: 0.04718728153860288\n",
      "Epoch ended at 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:56:20,812] Trial 14 finished with value: 0.05045963671183192 and parameters: {'lr': 0.01, 'num_epochs': 90, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.834661973941495\n",
      "re void: 0.050868640798826546\n",
      "reg:0.05045963671183192\n",
      "coefg:0.8426609051993037\n",
      "coefficient void: 0.8250902288340647\n",
      "re void: 0.054134326860797506\n",
      "coefficient void: 0.8247840283382503\n",
      "re void: 0.05020731616751891\n",
      "Epoch ended at 39\n",
      "coefficient void: 0.8630239902239076\n",
      "re void: 0.049899256494895156\n",
      "Epoch ended at 107\n",
      "coefficient void: 0.8863852307917698\n",
      "re void: 0.04415752950845165\n",
      "Epoch ended at 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 16:59:06,158] Trial 15 finished with value: 0.04984125114973582 and parameters: {'lr': 0.01, 'num_epochs': 110, 'batch_size': 16, 'l2_lambda': 0.3}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8346467363664164\n",
      "re void: 0.05080782671701586\n",
      "reg:0.04984125114973582\n",
      "coefg:0.8467860429108818\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 17:02:03,216] Trial 16 finished with value: 0.04963169993488552 and parameters: {'lr': 1e-05, 'num_epochs': 190, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 142\n",
      "coefficient void: 0.8264028341575513\n",
      "re void: 0.05399815026691385\n",
      "Epoch ended at 91\n",
      "coefficient void: 0.8275802226890963\n",
      "re void: 0.049817353737903025\n",
      "Epoch ended at 68\n",
      "coefficient void: 0.8858160468477724\n",
      "re void: 0.04660298709777082\n",
      "Epoch ended at 58\n",
      "coefficient void: 0.8735776661296872\n",
      "re void: 0.04672311806804679\n",
      "Epoch ended at 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 17:04:59,789] Trial 17 finished with value: 0.04963169993488552 and parameters: {'lr': 0.01, 'num_epochs': 170, 'batch_size': 16, 'l2_lambda': 0.5}. Best is trial 6 with value: 0.04963169993488552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8334279766582263\n",
      "re void: 0.05101689050379308\n",
      "reg:0.04963169993488552\n",
      "coefg:0.8493609492964668\n",
      "Epoch ended at 170\n",
      "coefficient void: 0.8293288748485119\n",
      "re void: 0.05370872371440862\n",
      "Epoch ended at 94\n",
      "coefficient void: 0.8364962725843298\n",
      "re void: 0.048809584410860335\n",
      "Epoch ended at 83\n",
      "coefficient void: 0.8884969047018068\n",
      "re void: 0.045122610319481324\n",
      "Epoch ended at 105\n",
      "coefficient void: 0.8837521738206012\n",
      "re void: 0.04428568174955477\n",
      "Epoch ended at 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 17:08:23,321] Trial 18 finished with value: 0.04835986832971669 and parameters: {'lr': 0.01, 'num_epochs': 230, 'batch_size': 16, 'l2_lambda': 0.3}. Best is trial 18 with value: 0.04835986832971669.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8421914814268882\n",
      "re void: 0.04987274145427838\n",
      "reg:0.04835986832971669\n",
      "coefg:0.8560531414764275\n",
      "Epoch ended at 170\n",
      "coefficient void: 0.8293288748485119\n",
      "re void: 0.05370872371440862\n",
      "Epoch ended at 94\n",
      "coefficient void: 0.8364962725843298\n",
      "re void: 0.048809584410860335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-18 17:10:23,211] Trial 19 failed with parameters: {'lr': 0.01, 'num_epochs': 230, 'batch_size': 16, 'l2_lambda': 0.3} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user01/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3949160/4199930222.py\", line 197, in objective\n",
      "    rloss=rloss+loss.item()*bx.size(0)\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-18 17:10:23,212] Trial 19 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=349'>350</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(reg_list)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=351'>352</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=352'>353</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=354'>355</a>\u001b[0m best_trial\u001b[39m=\u001b[39mstudy\u001b[39m.\u001b[39mbest_trial\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=355'>356</a>\u001b[0m best_rmse\u001b[39m=\u001b[39mbest_trial\u001b[39m.\u001b[39mvalue \n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     _optimize(\n\u001b[1;32m    491\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    492\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    493\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    494\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    495\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    496\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    497\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    498\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    499\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    500\u001b[0m     )\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         _optimize_sequential(\n\u001b[1;32m     68\u001b[0m             study,\n\u001b[1;32m     69\u001b[0m             func,\n\u001b[1;32m     70\u001b[0m             n_trials,\n\u001b[1;32m     71\u001b[0m             timeout,\n\u001b[1;32m     72\u001b[0m             catch,\n\u001b[1;32m     73\u001b[0m             callbacks,\n\u001b[1;32m     74\u001b[0m             gc_after_trial,\n\u001b[1;32m     75\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     77\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    165\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    206\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m     rloss\u001b[39m=\u001b[39mrloss\u001b[39m+\u001b[39mloss\u001b[39m.\u001b[39;49mitem()\u001b[39m*\u001b[39mbx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m eloss\u001b[39m=\u001b[39mrloss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(trainloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=198'>199</a>\u001b[0m tlosshistory\u001b[39m.\u001b[39mappend(eloss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml','r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "dataset_type=\"1d_raw_std\"\n",
    "target_type=\"gas\"\n",
    "x_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_train_{dataset_type}.npy\")\n",
    "t_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_train_{dataset_type}.npy\")\n",
    "x_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "t_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_test_{dataset_type}.npy\")\n",
    "\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/dataset\"\n",
    "odir=os.path.join(bdir,f\"outputs_issei2_{dataset_type}_{target_type}\")\n",
    "os.makedirs(odir,exist_ok=True)\n",
    "device=\"cuda:0\"\n",
    "W     = config['hyperparameter']['input_length']\n",
    "H     = config['hyperparameter']['input_height']\n",
    "C     = config['hyperparameter']['input_channel']\n",
    "dropout = config['hyperparameter']['dropout']\n",
    "ksize1 = config['hyperparameter']['ksize1']\n",
    "ksize2 = config['hyperparameter']['ksize2']\n",
    "stride1 = config['hyperparameter']['stride1']\n",
    "stride2 = config['hyperparameter']['stride2']\n",
    "maxpool = config['hyperparameter']['maxpool']\n",
    "SEED = config['hyperparameter']['seed']\n",
    "kfolds = config['hyperparameter']['kfolds']\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # CUDAがある場合\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class SimpleCNNissei(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, p, mid_channel=32):\n",
    "        super(SimpleCNNissei, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.p = p\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(4*input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1,32, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(self.p)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel*4).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,4*self.mid_channel*i:4*self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=ksize1, stride=stride1),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(maxpool),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=ksize2, stride=stride2),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(maxpool),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "\n",
    "def objective(trial):\n",
    "    curodir=os.path.join(odir,f\"case{trial.number}\")\n",
    "    wdir=os.path.join(curodir,\"weights\")\n",
    "    ldir=os.path.join(curodir,\"logs\")\n",
    "    os.makedirs(curodir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    lr    = trial.suggest_categorical(\"lr\",[1e-2,1e-3,1e-4,1e-5])\n",
    "    N     = trial.suggest_int(\"num_epochs\",50,250,step=100)\n",
    "    B     = trial.suggest_categorical(\"batch_size\",[16,32,64])\n",
    "    l2    = trial.suggest_categorical(\"l2_lambda\",[0.5,0.3,0.1])\n",
    "    earlystopmax=15\n",
    "    res_list=[]\n",
    "    coefs_list=[]\n",
    "    reg_list=[]\n",
    "    coefg_list=[]\n",
    "    set_seed(SEED)\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=SEED)\n",
    "    dataset=TensorDataset(x,t)\n",
    "    Nttl=len(dataset)\n",
    "    rng=np.random.default_rng()\n",
    "    xt=torch.from_numpy(x_test).float()\n",
    "    tt=torch.from_numpy(t_test).float()\n",
    "    testset=TensorDataset(xt,tt)\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    testsize=len(testset)\n",
    "    best_val_loss_list=[]\n",
    "\n",
    "    for k, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        trasize=len(train_idx)\n",
    "        valsize=len(val_idx)\n",
    "        testresult=np.zeros((2,valsize))\n",
    "        # trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "        trainset=Subset(dataset, train_idx)\n",
    "        valset = Subset(dataset, val_idx)\n",
    "        trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "        valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "        # testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "        model=SimpleCNNissei(W,C,l2).to(device)\n",
    "\n",
    "        # criterion=nn.HuberLoss(delta=delta)\n",
    "        criterion=nn.MSELoss()\n",
    "        optimizer=optim.Adam(params=model.parameters())\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "        tlosshistory=[]\n",
    "        vlosshistory=[]\n",
    "        veloss_best=10000\n",
    "        earlystopcount=0\n",
    "        epochttl=0\n",
    "\n",
    "        for epoch in range(N):\n",
    "            model.train()\n",
    "            rloss=0.0\n",
    "            for bx, by in trainloader:\n",
    "                # start_idx=rng.integers(250)\n",
    "                start_idx=0\n",
    "                bx=bx[:,:,start_idx:start_idx+W]\n",
    "                bx=bx.to(device)\n",
    "                by=by.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                o=model(bx)\n",
    "                loss=criterion(o,by)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                rloss=rloss+loss.item()*bx.size(0)\n",
    "            eloss=rloss/len(trainloader.dataset)\n",
    "            tlosshistory.append(eloss)\n",
    "\n",
    "            model.eval()\n",
    "            vrloss=0.0\n",
    "            with torch.no_grad():\n",
    "                for vx,vy in valloader:\n",
    "                    vx=vx[:,:,:W]\n",
    "                    vx=vx.to(device)\n",
    "                    vy=vy.to(device)\n",
    "                    vo=model(vx)\n",
    "                    vloss=criterion(vo,vy)\n",
    "                    vrloss+=vloss.item()*vx.size(0)\n",
    "            veloss=vrloss/len(valloader.dataset)\n",
    "            scheduler.step(veloss)\n",
    "            vlosshistory.append(veloss)\n",
    "            epochttl+=1\n",
    "            if veloss<veloss_best:\n",
    "                earlystopcount=0\n",
    "                veloss_best=veloss\n",
    "                torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "            else:\n",
    "                earlystopcount+=1\n",
    "            if earlystopcount==earlystopmax:\n",
    "                print(f\"Epoch ended at {epoch}\")\n",
    "                break\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, epochttl + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "        plt.plot(range(1, epochttl + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "        plt.title('Learning Curve (Log Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Log(Loss)')\n",
    "        plt.rcParams[\"font.size\"] = 16\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, epochttl + 1), tlosshistory, label='Train Loss')\n",
    "        plt.plot(range(1, epochttl + 1), vlosshistory, label='Validation Loss')\n",
    "        plt.title('Learning Curve (Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "        model=model.to(device)\n",
    "        model.eval()\n",
    "        pred=[]\n",
    "        targ=[]\n",
    "        with torch.no_grad():\n",
    "            for tx,ty in valloader:\n",
    "                tx=tx[:,:,:W]\n",
    "                tx=tx.to(device)\n",
    "                ty=ty.to(device)\n",
    "                o=model(tx)\n",
    "                pred.append(o.cpu())\n",
    "                targ.append(ty.cpu())\n",
    "        pred=torch.cat(pred,dim=0)\n",
    "        targ=torch.cat(targ,dim=0)\n",
    "\n",
    "        pred=pred.numpy()\n",
    "        targ=targ.numpy()\n",
    "\n",
    "        testresult[0,:]=targ\n",
    "        testresult[1,:]=pred\n",
    "        np.save(os.path.join(wdir,f'result{k}.npy'),testresult)\n",
    "\n",
    "        corr=np.corrcoef(targ,pred)\n",
    "        coef=corr[0,1]\n",
    "        print(f'coefficient void: {coef}')\n",
    "        re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "        print(f're void: {re}')\n",
    "        reg_list.append(re)\n",
    "        coefg_list.append(coef)\n",
    "\n",
    "        if target_type==\"gas\":\n",
    "            plt.figure(figsize=(8, 7))\n",
    "            plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "            plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "            plt.title('Predicted vs Actual Values')\n",
    "            plt.xlabel('Actual Value')\n",
    "            plt.ylabel('Predicted Value')\n",
    "            plt.xlim(0, 0.4)\n",
    "            plt.ylim(0, 0.4)\n",
    "            plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "            plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "            plt.rcParams[\"font.size\"] = 20\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "            plt.close()\n",
    "        if target_type==\"solid\":\n",
    "            plt.figure(figsize=(8, 7))\n",
    "            plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "            plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "            plt.title('Predicted vs Actual Values')\n",
    "            plt.xlabel('Actual Value')\n",
    "            plt.ylabel('Predicted Value')\n",
    "            plt.xlim(0, 0.06)\n",
    "            plt.ylim(0, 0.06)\n",
    "            plt.xticks([0,0.02,0.04,0.06])\n",
    "            plt.yticks([0,0.02,0.04,0.06])\n",
    "            plt.rcParams[\"font.size\"] = 20\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "            plt.close()\n",
    "\n",
    "    reg_list=np.array(reg_list)\n",
    "    coefg_list=np.array(coefg_list)\n",
    "    print(f\"reg:{np.mean(reg_list)}\")\n",
    "    print(f\"coefg:{np.mean(coefg_list)}\")\n",
    "    df = pl.DataFrame({\n",
    "        \"RMSE\":reg_list,\n",
    "        \"R2\":coefg_list\n",
    "    })\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    df = pl.concat([\n",
    "        df,\n",
    "        mean,\n",
    "        std\n",
    "    ])\n",
    "    df.write_csv(os.path.join(curodir,\"result.csv\"))\n",
    "    trial.set_user_attr(\"r2score\", np.mean(coefg_list))\n",
    "    trial.set_user_attr(\"rmse\", np.mean(reg_list))\n",
    "\n",
    "    config[\"best_hyperparameters\"]={\n",
    "        \"lr\":float(lr),\n",
    "        \"num_epochs\": int(N),\n",
    "        \"batch_size\": int(B),\n",
    "        \"l2_lambda\": float(l2),\n",
    "        \"metrics\": {\n",
    "            \"rmse\": float(np.mean(reg_list)),\n",
    "            \"r2\":float(np.mean(coefg_list))\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(curodir,\"config.yaml\"),\"w\") as f:\n",
    "        yaml.dump(config,f,default_flow_style=False,sort_keys=False)\n",
    "\n",
    "    return np.mean(reg_list)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_trial=study.best_trial\n",
    "best_rmse=best_trial.value \n",
    "best_params=best_trial.params\n",
    "best_r2 = best_trial.user_attrs[\"r2score\"]\n",
    "\n",
    "config[\"best_hyperparameters\"]={\n",
    "    \"lr\":float(best_params[\"lr\"]),\n",
    "    \"num_epochs\": int(best_params[\"num_epochs\"]),\n",
    "    \"batch_size\": int(best_params[\"batch_size\"]),\n",
    "    \"l2_lambda\": float(best_params[\"l2_lambda\"]),\n",
    "    \"metrics\": {\n",
    "            \"rmse\": float(best_rmse),\n",
    "            \"r2\":float(best_r2)\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(odir,\"config.yaml\"),\"w\") as f:\n",
    "    yaml.dump(config,f,default_flow_style=False,sort_keys=False)\n",
    "\n",
    "print(f\"Best trial number: {study.best_trial.number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 2, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3949160/4001690143.py:284: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8276567154900984\n",
      "re void: 0.05314686685477869\n",
      "coefficient void: 0.8344264355632872\n",
      "re void: 0.05080282976449638\n",
      "coefficient void: 0.8112926327284167\n",
      "re void: 0.05292191572631511\n",
      "coefficient void: 0.8686830780616257\n",
      "re void: 0.04674460111581632\n",
      "coefficient void: 0.8426584797630101\n",
      "re void: 0.055700303090595135\n",
      "coefficient void: 0.8569342215703812\n",
      "re void: 0.04978364554321218\n",
      "Epoch ended at 33\n",
      "coefficient void: 0.8364896475954718\n",
      "re void: 0.056882948125049654\n",
      "Epoch ended at 108\n",
      "coefficient void: 0.8658265498340568\n",
      "re void: 0.04892591456837374\n",
      "Epoch ended at 134\n",
      "coefficient void: 0.8897192967093844\n",
      "re void: 0.04287995492162307\n",
      "Epoch ended at 72\n",
      "coefficient void: 0.890480726442055\n",
      "re void: 0.0520558674809485\n",
      "reg_list:[0.05314687 0.05080283 0.05292192 0.0467446  0.0557003  0.04978365\n",
      " 0.05688295 0.04892591 0.04287995 0.05205587]\n",
      "coefg_list:[0.82765672 0.83442644 0.81129263 0.86868308 0.84265848 0.85693422\n",
      " 0.83648965 0.86582655 0.8897193  0.89048073]\n",
      "reg:0.050984484719120884\n",
      "coefg:0.8524167783757788\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "dataset_type=\"1d_raw_std\"\n",
    "target_name=\"relative_ratiowww\"\n",
    "target_type=\"gas\"\n",
    "x_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_train_{dataset_type}.npy\")\n",
    "t_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_train_{dataset_type}.npy\")\n",
    "x_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "t_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_test_{dataset_type}.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/dataset\"\n",
    "odir=os.path.join(bdir,f\"outputs_issei2_{dataset_type}_{target_type}\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=16\n",
    "W=2500\n",
    "H=49\n",
    "lr=0.0001\n",
    "N=150\n",
    "l1=1e-7\n",
    "# l2=5e-5\n",
    "l2=0.3\n",
    "delta=0.01\n",
    "C=2\n",
    "SEED=93\n",
    "p=0.3\n",
    "earlystopmax=15\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=51),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=51),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class SimpleCNNissei(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, p, mid_channel=32):\n",
    "        super(SimpleCNNissei, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.p = p\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(4*input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(self.p)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel*4).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,4*self.mid_channel*i:4*self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class SimpleCNN2d(nn.Module):\n",
    "    def __init__(self, input_width, input_height, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN2d, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(1, mid_channel, kernel_size=16),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(mid_channel, mid_channel, kernel_size=4),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # CUDAがある場合\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "xt=torch.from_numpy(x_test).float()\n",
    "tt=torch.from_numpy(t_test).float()\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "testset=TensorDataset(xt,tt)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.8*Nttl)\n",
    "valsize=Nttl-trasize\n",
    "# testsize=Nttl-trasize-valsize\n",
    "set_seed(SEED)\n",
    "\n",
    "for k in range(10):\n",
    "    cur_seed=SEED+k\n",
    "    gen_split=torch.Generator()\n",
    "    gen_split.manual_seed(cur_seed)\n",
    "    testresult=np.zeros((2,valsize))\n",
    "    trainset,valset=random_split(dataset,[trasize,valsize],generator=gen_split)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNNissei(W,C,p).to(device)\n",
    "    # params = 0\n",
    "    # for p in model.parameters():\n",
    "    #     if p.requires_grad:\n",
    "    #         params += p.numel()\n",
    "            \n",
    "    # print(params)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "    loaded_target=[]\n",
    "    veloss_best=10000\n",
    "    earlystopcount=0\n",
    "    epochttl=0\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "\n",
    "    for epoch in range(N):\n",
    "        cur_seed=SEED*2+200*k+epoch\n",
    "        gen_loader=torch.Generator()\n",
    "        gen_loader.manual_seed(cur_seed)\n",
    "        trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            first_by=by[0].item()\n",
    "            loaded_target.append(first_by)\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            # l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            # l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            # loss=loss+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        scheduler.step(veloss)\n",
    "        vlosshistory.append(veloss)\n",
    "        epochttl+=1\n",
    "        if veloss<veloss_best:\n",
    "            earlystopcount=0\n",
    "            veloss_best=veloss\n",
    "            torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "        else:\n",
    "            earlystopcount+=1\n",
    "        if earlystopcount==earlystopmax:\n",
    "            print(f\"Epoch ended at {epoch}\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epochttl + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, epochttl + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epochttl + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, epochttl + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in valloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "    loaded_target=np.array(loaded_target)\n",
    "\n",
    "    testresult[0,:]=targ\n",
    "    testresult[1,:]=pred\n",
    "    df = pl.DataFrame({\n",
    "        \"target\":targ,\n",
    "        \"prediction\":pred\n",
    "    })\n",
    "    np.save(os.path.join(wdir,f'result{k}.npy'),testresult)\n",
    "    df.write_csv(os.path.join(wdir,f\"result_val{k}.csv\"))\n",
    "    df = pl.DataFrame({\n",
    "        \"target\":loaded_target\n",
    "    })\n",
    "    df.write_csv(os.path.join(wdir,f\"label_train{k}.csv\"))\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    if target_name==\"relative_ratio\" or target_name==\"relative_ratio_lowgas\" or target_name==\"relative_ratio_highgas\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks([0,0.25,0.5,0.75,1.0])\n",
    "        plt.yticks([0,0.25,0.5,0.75,1.0])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    elif target_type == \"gas\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.4)\n",
    "        plt.ylim(0, 0.4)\n",
    "        plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "    elif target_type == \"solid\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.06)\n",
    "        plt.ylim(0, 0.06)\n",
    "        plt.xticks([0,0.02,0.04,0.06])\n",
    "        plt.yticks([0,0.02,0.04,0.06])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n",
    "df = pl.DataFrame({\n",
    "    \"RMSE\":reg_list,\n",
    "    \"R2\":coefg_list\n",
    "})\n",
    "mean = df.mean()\n",
    "std = df.std()\n",
    "\n",
    "df = pl.concat([\n",
    "    df,\n",
    "    mean,\n",
    "    std\n",
    "])\n",
    "df.write_csv(os.path.join(odir,\"result.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sdb/yyamaguchi/simulationB4/dataset/outputs_issei_1d_bp_std_gas/weights\n",
      "/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_1d_bp_std.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3925435/1231364475.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.8010008159444832\n",
      "re void: 0.05703502079739214\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "\n",
    "print(wdir)\n",
    "model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "print(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "x_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "t_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_test_{dataset_type}.npy\")\n",
    "xt=torch.from_numpy(x_test).float().to(device)\n",
    "tt=torch.from_numpy(t_test).float().to(device)\n",
    "testset=TensorDataset(xt,tt)\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "testresult=np.zeros((2,len(testset)))\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "pred=[]\n",
    "targ=[]\n",
    "with torch.no_grad():\n",
    "    for tx,ty in testloader:\n",
    "        tx=tx.to(device)\n",
    "        ty=ty.to(device)\n",
    "        o=model(tx)\n",
    "        pred.append(o.cpu())\n",
    "        targ.append(ty.cpu())\n",
    "pred=torch.cat(pred,dim=0)\n",
    "targ=torch.cat(targ,dim=0)\n",
    "\n",
    "pred=pred.numpy()\n",
    "targ=targ.numpy()\n",
    "\n",
    "testresult[0,:]=targ\n",
    "testresult[1,:]=pred\n",
    "np.save(os.path.join(odir,f'result{k}.npy'),testresult)\n",
    "\n",
    "corr=np.corrcoef(targ,pred)\n",
    "coef=corr[0,1]\n",
    "print(f'coefficient void: {coef}')\n",
    "# re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "print(f're void: {re}')\n",
    "\n",
    "if target_type == \"gas\":\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "    plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(odir, f'val_pred_vs_actual{k}.png'))\n",
    "    plt.close()\n",
    "if target_type == \"solid\":\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.06)\n",
    "    plt.ylim(0, 0.06)\n",
    "    plt.xticks([0,0.02,0.04,0.06])\n",
    "    plt.yticks([0,0.02,0.04,0.06])\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(odir, f'val_pred_vs_actual{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"RMSE\":re,\n",
    "    \"R2\":coef\n",
    "})\n",
    "df.write_csv(os.path.join(odir,f\"testresult{k}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315,)\n",
      "torch.Size([315, 2, 2500])\n",
      "109569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2655947/2685038901.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8824124055828574\n",
      "re void: 0.05639940174478198\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8268349212650058\n",
      "re void: 0.04836358986678468\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.7722871357632052\n",
      "re void: 0.08717179392790182\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8592132125335791\n",
      "re void: 0.05236340955419495\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.7673884432768617\n",
      "re void: 0.06572777424459388\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8442819833311496\n",
      "re void: 0.06772545756913823\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8571095467766693\n",
      "re void: 0.07162785696070464\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8705517515826754\n",
      "re void: 0.04631580151889192\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8474515395119966\n",
      "re void: 0.05801332471112415\n",
      "109569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=214'>215</a>\u001b[0m vx\u001b[39m=\u001b[39mvx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=215'>216</a>\u001b[0m vy\u001b[39m=\u001b[39mvy\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=216'>217</a>\u001b[0m vo\u001b[39m=\u001b[39mmodel(vx)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=217'>218</a>\u001b[0m vloss\u001b[39m=\u001b[39mcriterion(vo,vy)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=218'>219</a>\u001b[0m vrloss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mvloss\u001b[39m.\u001b[39mitem()\u001b[39m*\u001b[39mvx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     output[:,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39mi:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)] \u001b[39m=\u001b[39m x\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_env_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/tg_train_two_env_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2env_std\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=32\n",
    "W=2500\n",
    "lr=0.001\n",
    "N=50\n",
    "l1=1e-7\n",
    "l2=1e-6\n",
    "C=2\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(input_length,mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, input_length, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.input_channel = input_channel\n",
    "#         self.input_length = input_length\n",
    "#         self.mid_channel = mid_channel\n",
    "#         self.conv1 = nn.Conv1d(1, mid_channel, kernel_size=201)\n",
    "#         self.bn1 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.maxpool1 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(mid_channel, mid_channel, kernel_size=51)\n",
    "#         self.bn2 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.fc = nn.Linear(mid_channel*input_channel, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "#         # self.ln1 = nn.LayerNorm([16, input_length])\n",
    "#         # self.ln2 = nn.LayerNorm([4, input_length+2])\n",
    "#     def forward(self, xall):\n",
    "#         bsize = xall.shape[0]\n",
    "#         output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "#         for i in range(self.input_channel):\n",
    "#             x = xall[:,i,:]\n",
    "#             x = x.unsqueeze(1)\n",
    "#             x = self.conv1(x)\n",
    "#             x = self.bn1(x)\n",
    "#             x = self.relu1(x)\n",
    "#             x = self.maxpool1(x)\n",
    "#             # x = self.ln1(x)\n",
    "#             x = self.conv2(x)\n",
    "#             x = self.bn2(x)\n",
    "#             x = self.relu2(x)\n",
    "#             x = self.maxpool2(x)\n",
    "#             # x = self.ln2(x)\n",
    "#             x = self.pool(x)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "#         output = self.fc(output)\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "class GradCAM1d:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_backward_hook(backward_hook))\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        self.model.eval()\n",
    "        input_tensor = input_tensor.to(next(self.model.parameters()).device)\n",
    "        self.model.zero_grad()\n",
    "        out = self.model(input_tensor)\n",
    "        print(out)\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            out = out[0]\n",
    "        target = out.squeeze()\n",
    "        print(target)\n",
    "        if target.ndim > 0:\n",
    "            target = target.sum()\n",
    "        self.model.zero_grad()\n",
    "        target.backward(retain_graph=True)\n",
    "        gradients = self.gradients         # [B, C, L]\n",
    "        print(gradients.shape)\n",
    "        activations = self.activations     # [B, C, L]\n",
    "        print(activations.shape)\n",
    "        weights = gradients.mean(dim=2, keepdim=True)  # [B, C, 1]\n",
    "        grad_cam_map = (weights * activations).sum(dim=1, keepdim=True)  # (B,1,L)\n",
    "        grad_cam_map = torch.relu(grad_cam_map)\n",
    "        grad_cam_map = torch.nn.functional.interpolate(\n",
    "            grad_cam_map, size=input_tensor.shape[2], mode='linear', align_corners=False\n",
    "        )\n",
    "        grad_cam_map = grad_cam_map.squeeze().cpu().numpy()\n",
    "        grad_cam_map = (grad_cam_map - grad_cam_map.min()) / (grad_cam_map.max() - grad_cam_map.min() + 1e-8)\n",
    "        return grad_cam_map\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "print(x_train.shape)\n",
    "# x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(t_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "xgradcam=x[50,:,:]\n",
    "xgradcam=xgradcam.unsqueeze(0)\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "\n",
    "for k in range(10):\n",
    "    trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNN(W,C).to(device)\n",
    "    params = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            params += p.numel()\n",
    "            \n",
    "    print(params)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            # l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "    print(targ.shape)\n",
    "\n",
    "    # corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient solid: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    # print(f're solid: {re}')\n",
    "    # res_list.append(re)\n",
    "    # coefs_list.append(coef)\n",
    "    # corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient void: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    # print(f're void: {re}')\n",
    "    # reg_list.append(re)\n",
    "    # coefg_list.append(coef)\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    # plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(-0.0, 0.05)\n",
    "    # plt.ylim(-0.0, 0.05)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    # plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(0, 0.4)\n",
    "    # plt.ylim(0, 0.4)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ, pred, alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # target_layer = None\n",
    "    # if hasattr(model, 'conv3'):\n",
    "    #     target_layer = model.conv3\n",
    "    # elif hasattr(model, 'layer3'):\n",
    "    #     target_layer = model.layer3\n",
    "    # else:\n",
    "    #     for m in reversed(list(model.modules())):\n",
    "    #         if isinstance(m, torch.nn.Conv1d):\n",
    "    #             target_layer = m\n",
    "    #             break\n",
    "    # if target_layer is None:\n",
    "    #     raise RuntimeError(\"Could not find a suitable layer for Grad-CAM.\")\n",
    "\n",
    "    # gradcam_output_dir = os.path.join(odir, \"gradcam\")\n",
    "    # gradcam = GradCAM1d(model, target_layer)\n",
    "    # grad_cam_map = gradcam(xgradcam)\n",
    "    # gradcam.remove_hooks()\n",
    "\n",
    "    # plt.figure(figsize=(10,6))\n",
    "    # plt.rcParams['font.size'] = 20\n",
    "    # amp=10\n",
    "    # ta=np.arange(W)\n",
    "    # xgradcam=xgradcam.detach().cpu()\n",
    "    # xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    # plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    # plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    # grad_cam_map *= 30\n",
    "    # grad_cam_map -= amp\n",
    "    # plt.legend(loc='upper right')\n",
    "    # plt.plot(ta,grad_cam_map[:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, grad_cam_map[:],-amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.xlabel('Time Axis')\n",
    "    # plt.ylabel('Pressure [-]')\n",
    "    # plt.ylim(-amp,2*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # # plt.ylim(-amp,5*amp)\n",
    "    # # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.xlim(0,W)\n",
    "    # plt.grid(True)\n",
    "    # # plt.xlim(35,40)\n",
    "    # plt.tight_layout()\n",
    "    # new_save_path = os.path.join(odir, f\"gradcam{k}.png\")\n",
    "    # plt.savefig(new_save_path)\n",
    "    # plt.close()\n",
    "\n",
    "    # model.eval()\n",
    "    # model.zero_grad()\n",
    "\n",
    "    # # 1. まずデバイスに送る\n",
    "    # xgradcam = xgradcam.to(device)\n",
    "\n",
    "    # # 2. デバイス移動「後」に勾配追跡をONにする\n",
    "    # xgradcam.requires_grad_()\n",
    "\n",
    "    # # 3. 予測\n",
    "    # output = model(xgradcam)\n",
    "\n",
    "    # # 4. 逆伝播（クラス1に注目する場合）\n",
    "    # loss = output[0]\n",
    "    # loss.backward()\n",
    "\n",
    "    # # 5. 勾配を取り出す（.gradプロパティに格納されている）\n",
    "    # if xgradcam.grad is not None:\n",
    "    #     grads = xgradcam.grad.data # ここで [1, 5, 2500] が取得できる\n",
    "        \n",
    "    #     # --- チャネル別重要度スコアの計算 ---\n",
    "    #     # abs()をとって時間方向に平均\n",
    "    #     salimap = grads.abs().squeeze(0)\n",
    "        \n",
    "    #     # 0~1に正規化（安全のために 1e-8 を足す）\n",
    "    #     salimap = salimap / (salimap.max() + 1e-8)\n",
    "        \n",
    "    #     salimap = salimap.cpu().numpy()\n",
    "    #     salimap = salimap*10\n",
    "    #     print(salimap.shape)\n",
    "    # else:\n",
    "    #     print(\"勾配が取得できませんでした。requires_gradの位置を確認してください。\")\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(10,6))\n",
    "    # plt.rcParams['font.size'] = 20\n",
    "    # amp=10\n",
    "    # xgradcam=xgradcam.detach().cpu()\n",
    "    # xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    # plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    # plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    # plt.legend(loc='upper right')\n",
    "    # plt.plot(ta,salimap[0,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, salimap[0,:],0,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.plot(ta,amp+salimap[1,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, amp+salimap[1,:],amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,2*amp+salimap[2,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 2*amp+salimap[2,:],2*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,3*amp+salimap[3,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 3*amp+salimap[3,:],3*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,4*amp+salimap[4,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 4*amp+salimap[4,:],4*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # plt.xlabel('Time Axis')\n",
    "    # plt.ylabel('Pressure [-]')\n",
    "    # plt.ylim(-amp,2*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # # plt.ylim(-amp,5*amp)\n",
    "    # # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.xlim(0,W)\n",
    "    # plt.grid(True)\n",
    "    # # plt.xlim(35,40)\n",
    "    # plt.tight_layout()\n",
    "    # new_save_path = os.path.join(odir, f\"saliency{k}.png\")\n",
    "    # plt.savefig(new_save_path)\n",
    "    # plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315, 5000)\n",
      "torch.Size([315, 5000])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m l1n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m l2n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m loss\u001b[39m=\u001b[39mloss\u001b[39m+\u001b[39ml1\u001b[39m*\u001b[39ml1n\u001b[39m+\u001b[39ml2\u001b[39m*\u001b[39ml2n\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l1' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_raw_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/t_train_two_raw_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2raw_std_nn\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=64\n",
    "W=2500\n",
    "lr=0.001\n",
    "N=100\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_length,4096)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096,2)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "\n",
    "for k in range(10):\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=B,shuffle=False)\n",
    "    model=SimpleNN(W*C).to(device)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l1*l1n+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "\n",
    "    corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient solid: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    print(f're solid: {re}')\n",
    "    res_list.append(re)\n",
    "    coefs_list.append(coef)\n",
    "    corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(-0.0, 0.05)\n",
    "    plt.ylim(-0.0, 0.05)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
