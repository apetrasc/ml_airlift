{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 2, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3580120/433510039.py:258: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.22251630318990268\n",
      "re void: 0.01415292249122316\n",
      "coefficient void: 0.2993000486567635\n",
      "re void: 0.01577356319409036\n",
      "coefficient void: 0.10676467926155782\n",
      "re void: 0.01651369375802633\n",
      "coefficient void: 0.2370725910119064\n",
      "re void: 0.013988928729843293\n",
      "coefficient void: 0.3541958521843564\n",
      "re void: 0.014851504652820948\n",
      "coefficient void: 0.23385982125398472\n",
      "re void: 0.019423056594722477\n",
      "coefficient void: 0.4046976938639121\n",
      "re void: 0.01539729604465758\n",
      "coefficient void: 0.08076455743509421\n",
      "re void: 0.01754540297970157\n",
      "coefficient void: 0.0388416983258192\n",
      "re void: 0.016684603751680144\n",
      "coefficient void: 0.38354176545761914\n",
      "re void: 0.013053321820990364\n",
      "reg_list:[0.01415292 0.01577356 0.01651369 0.01398893 0.0148515  0.01942306\n",
      " 0.0153973  0.0175454  0.0166846  0.01305332]\n",
      "coefg_list:[0.2225163  0.29930005 0.10676468 0.23707259 0.35419585 0.23385982\n",
      " 0.40469769 0.08076456 0.0388417  0.38354177]\n",
      "reg:0.015738429401775625\n",
      "coefg:0.2361555010640916\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml','r') as file:\n",
    "    config=yaml.safe_load(file)\n",
    "dataset_type=\"1d_raw_std\"\n",
    "target_type=\"gas\"\n",
    "x_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_train_{dataset_type}.npy\")\n",
    "t_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_train_{dataset_type}.npy\")\n",
    "# x_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/x_test_{dataset_type}.npy\")\n",
    "# t_test=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/dataset/npy/tg_test_{dataset_type}.npy\")\n",
    "\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/dataset\"\n",
    "odir=os.path.join(bdir,f\"outputs_{dataset_type}_{target_type}\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B     = config['hyperparameter']['batch_size']\n",
    "W     = config['hyperparameter']['input_length']\n",
    "H     = config['hyperparameter']['input_height']\n",
    "lr    = config['hyperparameter']['learning_rate']\n",
    "N     = config['hyperparameter']['num_epochs']\n",
    "l2    = config['hyperparameter']['l2_lambda']\n",
    "delta = config['hyperparameter']['huber_delta']\n",
    "C     = config['hyperparameter']['input_channel']\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class SimpleCNN2d(nn.Module):\n",
    "    def __init__(self, input_width, input_height, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN2d, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(1, mid_channel, kernel_size=16),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(mid_channel, mid_channel, kernel_size=4),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.input_channel = input_channel\n",
    "#         self.input_length = input_length\n",
    "#         self.mid_channel = mid_channel\n",
    "#         self.conv1 = nn.Conv1d(1, mid_channel, kernel_size=201)\n",
    "#         self.bn1 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.maxpool1 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(mid_channel, mid_channel, kernel_size=51)\n",
    "#         self.bn2 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.fc = nn.Linear(mid_channel*input_channel, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "#         # self.ln1 = nn.LayerNorm([16, input_length])\n",
    "#         # self.ln2 = nn.LayerNorm([4, input_length+2])\n",
    "#     def forward(self, xall):\n",
    "#         bsize = xall.shape[0]\n",
    "#         output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "#         for i in range(self.input_channel):\n",
    "#             x = xall[:,i,:]\n",
    "#             x = x.unsqueeze(1)\n",
    "#             x = self.conv1(x)\n",
    "#             x = self.bn1(x)\n",
    "#             x = self.relu1(x)\n",
    "#             x = self.maxpool1(x)\n",
    "#             # x = self.ln1(x)\n",
    "#             x = self.conv2(x)\n",
    "#             x = self.bn2(x)\n",
    "#             x = self.relu2(x)\n",
    "#             x = self.maxpool2(x)\n",
    "#             # x = self.ln2(x)\n",
    "#             x = self.pool(x)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "#         output = self.fc(output)\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "rng=np.random.default_rng()\n",
    "# xt=torch.from_numpy(x_test).float()\n",
    "# tt=torch.from_numpy(t_test).float()\n",
    "# testset=TensorDataset(xt,tt)\n",
    "# testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "# testsize=len(testset)\n",
    "\n",
    "for k in range(10):\n",
    "    testresult=np.zeros((2,testsize))\n",
    "    trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNN(W,C).to(device)\n",
    "    # params = 0\n",
    "    # for p in model.parameters():\n",
    "    #     if p.requires_grad:\n",
    "    #         params += p.numel()\n",
    "            \n",
    "    # print(params)\n",
    "\n",
    "    criterion=nn.HuberLoss(delta=delta)\n",
    "    # criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            # start_idx=rng.integers(250)\n",
    "            start_idx=0\n",
    "            bx=bx[:,:,start_idx:start_idx+W]\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            # l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l2*l2n*0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx[:,:,:W]\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx[:,:,:W]\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    testresult[0,:]=targ\n",
    "    testresult[1,:]=pred\n",
    "    np.save(os.path.join(wdir,f'result{k}.npy'),testresult)\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    if target_type == \"gas\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.4)\n",
    "        plt.ylim(0, 0.4)\n",
    "        plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "    if target_type == \"solid\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.06)\n",
    "        plt.ylim(0, 0.06)\n",
    "        plt.xticks([0,0.02,0.04,0.06])\n",
    "        plt.yticks([0,0.02,0.04,0.06])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n",
    "df = pl.DataFrame({\n",
    "    \"RMSE\":reg_list,\n",
    "    \"R2\":coefg_list\n",
    "})\n",
    "mean = df.mean()\n",
    "std = df.std()\n",
    "\n",
    "df = pl.concat([\n",
    "    df,\n",
    "    mean,\n",
    "    std\n",
    "])\n",
    "df.write_csv(os.path.join(odir,\"result.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 2, 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3438451/2932046310.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient void: 0.3469683908191165\n",
      "re void: 0.018440722598173864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=202'>203</a>\u001b[0m vx\u001b[39m=\u001b[39mvx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=203'>204</a>\u001b[0m vy\u001b[39m=\u001b[39mvy\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=204'>205</a>\u001b[0m vo\u001b[39m=\u001b[39mmodel(vx)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=205'>206</a>\u001b[0m vloss\u001b[39m=\u001b[39mcriterion(vo,vy)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=206'>207</a>\u001b[0m vrloss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mvloss\u001b[39m.\u001b[39mitem()\u001b[39m*\u001b[39mvx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m x \u001b[39m=\u001b[39m xall[:,i]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels[i](x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m output[:,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39mi:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)] \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39m=\u001b[39m OrderedDict()\n\u001b[1;32m   1709\u001b[0m \u001b[39m# On the return type:\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[39m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[39m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1716\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m   1717\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1718\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "dataset_type=\"two_raw_std\"\n",
    "target_type=\"solid\"\n",
    "x_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_{dataset_type}.npy\")\n",
    "t_train=np.load(f\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/ts_train_{dataset_type}.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,f\"outputs_{dataset_type}_{target_type}\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=32\n",
    "W=2500\n",
    "H=49\n",
    "lr=0.01\n",
    "N=50\n",
    "l1=1e-7\n",
    "l2=1e-6\n",
    "delta=0.01\n",
    "C=2\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "class SimpleCNN2d(nn.Module):\n",
    "    def __init__(self, input_width, input_height, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN2d, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(1, mid_channel, kernel_size=16),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(mid_channel, mid_channel, kernel_size=4),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.input_channel = input_channel\n",
    "#         self.input_length = input_length\n",
    "#         self.mid_channel = mid_channel\n",
    "#         self.conv1 = nn.Conv1d(1, mid_channel, kernel_size=201)\n",
    "#         self.bn1 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.maxpool1 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(mid_channel, mid_channel, kernel_size=51)\n",
    "#         self.bn2 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.fc = nn.Linear(mid_channel*input_channel, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "#         # self.ln1 = nn.LayerNorm([16, input_length])\n",
    "#         # self.ln2 = nn.LayerNorm([4, input_length+2])\n",
    "#     def forward(self, xall):\n",
    "#         bsize = xall.shape[0]\n",
    "#         output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "#         for i in range(self.input_channel):\n",
    "#             x = xall[:,i,:]\n",
    "#             x = x.unsqueeze(1)\n",
    "#             x = self.conv1(x)\n",
    "#             x = self.bn1(x)\n",
    "#             x = self.relu1(x)\n",
    "#             x = self.maxpool1(x)\n",
    "#             # x = self.ln1(x)\n",
    "#             x = self.conv2(x)\n",
    "#             x = self.bn2(x)\n",
    "#             x = self.relu2(x)\n",
    "#             x = self.maxpool2(x)\n",
    "#             # x = self.ln2(x)\n",
    "#             x = self.pool(x)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "#         output = self.fc(output)\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "\n",
    "for k in range(10):\n",
    "    testresult=np.zeros((2,testsize))\n",
    "    trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNN(W,C).to(device)\n",
    "    # params = 0\n",
    "    # for p in model.parameters():\n",
    "    #     if p.requires_grad:\n",
    "    #         params += p.numel()\n",
    "            \n",
    "    # print(params)\n",
    "\n",
    "    criterion=nn.HuberLoss(delta=delta)\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            # l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            # l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            # loss=loss+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    testresult[0,:]=targ\n",
    "    testresult[1,:]=pred\n",
    "    np.save(os.path.join(wdir,f'result{k}.npy'),testresult)\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    if target_type == \"gas\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.4)\n",
    "        plt.ylim(0, 0.4)\n",
    "        plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.yticks([0,0.1,0.2,0.3,0.4])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "    if target_type == \"solid\":\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        plt.scatter(targ, pred, alpha=0.6, marker='o', label='Phase fraction')\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "        plt.title('Predicted vs Actual Values')\n",
    "        plt.xlabel('Actual Value')\n",
    "        plt.ylabel('Predicted Value')\n",
    "        plt.xlim(0, 0.06)\n",
    "        plt.ylim(0, 0.06)\n",
    "        plt.xticks([0,0.02,0.04,0.06])\n",
    "        plt.yticks([0,0.02,0.04,0.06])\n",
    "        plt.rcParams[\"font.size\"] = 20\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "        plt.close()\n",
    "\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n",
    "df = pl.DataFrame({\n",
    "    \"RMSE\":reg_list,\n",
    "    \"R2\":coefg_list\n",
    "})\n",
    "mean = df.mean()\n",
    "std = df.std()\n",
    "\n",
    "df = pl.concat([\n",
    "    df,\n",
    "    mean,\n",
    "    std\n",
    "])\n",
    "df.write_csv(os.path.join(odir,\"result.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315,)\n",
      "torch.Size([315, 2, 2500])\n",
      "109569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2655947/2685038901.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8824124055828574\n",
      "re void: 0.05639940174478198\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8268349212650058\n",
      "re void: 0.04836358986678468\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.7722871357632052\n",
      "re void: 0.08717179392790182\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8592132125335791\n",
      "re void: 0.05236340955419495\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.7673884432768617\n",
      "re void: 0.06572777424459388\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8442819833311496\n",
      "re void: 0.06772545756913823\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8571095467766693\n",
      "re void: 0.07162785696070464\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8705517515826754\n",
      "re void: 0.04631580151889192\n",
      "109569\n",
      "(48,)\n",
      "(48,)\n",
      "coefficient void: 0.8474515395119966\n",
      "re void: 0.05801332471112415\n",
      "109569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=214'>215</a>\u001b[0m vx\u001b[39m=\u001b[39mvx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=215'>216</a>\u001b[0m vy\u001b[39m=\u001b[39mvy\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=216'>217</a>\u001b[0m vo\u001b[39m=\u001b[39mmodel(vx)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=217'>218</a>\u001b[0m vloss\u001b[39m=\u001b[39mcriterion(vo,vy)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=218'>219</a>\u001b[0m vrloss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mvloss\u001b[39m.\u001b[39mitem()\u001b[39m*\u001b[39mvx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     output[:,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39mi:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmid_channel\u001b[39m*\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)] \u001b[39m=\u001b[39m x\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Document/yyamaguchi/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_env_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/tg_train_two_env_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2env_std\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=32\n",
    "W=2500\n",
    "lr=0.001\n",
    "N=50\n",
    "l1=1e-7\n",
    "l2=1e-6\n",
    "C=2\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.input_length = input_length\n",
    "        self.mid_channel = mid_channel\n",
    "        self.models = nn.ModuleList([\n",
    "            self._build_sub_network(input_length,mid_channel) for _ in range(input_channel)\n",
    "        ])\n",
    "        self.fc = nn.Linear(input_channel*mid_channel,1)\n",
    "        # self.ln1 = nn.LayerNorm([mid_channel, int(input_length/5)])\n",
    "        # self.ln2 = nn.LayerNorm([mid_channel, int(input_length/25)])\n",
    "    def _build_sub_network(self, input_length, mid_channel):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(mid_channel, mid_channel, kernel_size=201),\n",
    "            nn.BatchNorm1d(mid_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, xall):\n",
    "        bsize = xall.shape[0]\n",
    "        output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "        for i in range(self.input_channel):\n",
    "            x = xall[:,i]\n",
    "            x = x.unsqueeze(1)\n",
    "            x = self.models[i](x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "        output = self.fc(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, input_length, input_channel, mid_channel=16):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         self.input_channel = input_channel\n",
    "#         self.input_length = input_length\n",
    "#         self.mid_channel = mid_channel\n",
    "#         self.conv1 = nn.Conv1d(1, mid_channel, kernel_size=201)\n",
    "#         self.bn1 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.maxpool1 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(mid_channel, mid_channel, kernel_size=51)\n",
    "#         self.bn2 = nn.BatchNorm1d(mid_channel)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool1d(4,stride=1)\n",
    "#         self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "#         self.fc = nn.Linear(mid_channel*input_channel, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "#         # self.ln1 = nn.LayerNorm([16, input_length])\n",
    "#         # self.ln2 = nn.LayerNorm([4, input_length+2])\n",
    "#     def forward(self, xall):\n",
    "#         bsize = xall.shape[0]\n",
    "#         output = torch.zeros(bsize,self.input_channel*self.mid_channel).to(device)\n",
    "#         for i in range(self.input_channel):\n",
    "#             x = xall[:,i,:]\n",
    "#             x = x.unsqueeze(1)\n",
    "#             x = self.conv1(x)\n",
    "#             x = self.bn1(x)\n",
    "#             x = self.relu1(x)\n",
    "#             x = self.maxpool1(x)\n",
    "#             # x = self.ln1(x)\n",
    "#             x = self.conv2(x)\n",
    "#             x = self.bn2(x)\n",
    "#             x = self.relu2(x)\n",
    "#             x = self.maxpool2(x)\n",
    "#             # x = self.ln2(x)\n",
    "#             x = self.pool(x)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             output[:,self.mid_channel*i:self.mid_channel*(i+1)] = x\n",
    "#         output = self.fc(output)\n",
    "#         return output.squeeze(1)\n",
    "\n",
    "class GradCAM1d:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_backward_hook(backward_hook))\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        self.model.eval()\n",
    "        input_tensor = input_tensor.to(next(self.model.parameters()).device)\n",
    "        self.model.zero_grad()\n",
    "        out = self.model(input_tensor)\n",
    "        print(out)\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            out = out[0]\n",
    "        target = out.squeeze()\n",
    "        print(target)\n",
    "        if target.ndim > 0:\n",
    "            target = target.sum()\n",
    "        self.model.zero_grad()\n",
    "        target.backward(retain_graph=True)\n",
    "        gradients = self.gradients         # [B, C, L]\n",
    "        print(gradients.shape)\n",
    "        activations = self.activations     # [B, C, L]\n",
    "        print(activations.shape)\n",
    "        weights = gradients.mean(dim=2, keepdim=True)  # [B, C, 1]\n",
    "        grad_cam_map = (weights * activations).sum(dim=1, keepdim=True)  # (B,1,L)\n",
    "        grad_cam_map = torch.relu(grad_cam_map)\n",
    "        grad_cam_map = torch.nn.functional.interpolate(\n",
    "            grad_cam_map, size=input_tensor.shape[2], mode='linear', align_corners=False\n",
    "        )\n",
    "        grad_cam_map = grad_cam_map.squeeze().cpu().numpy()\n",
    "        grad_cam_map = (grad_cam_map - grad_cam_map.min()) / (grad_cam_map.max() - grad_cam_map.min() + 1e-8)\n",
    "        return grad_cam_map\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "print(x_train.shape)\n",
    "# x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(t_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "xgradcam=x[50,:,:]\n",
    "xgradcam=xgradcam.unsqueeze(0)\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "\n",
    "for k in range(10):\n",
    "    trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "    testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=1,shuffle=False)\n",
    "    model=SimpleCNN(W,C).to(device)\n",
    "    params = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            params += p.numel()\n",
    "            \n",
    "    print(params)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            # l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "    print(targ.shape)\n",
    "\n",
    "    # corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient solid: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    # print(f're solid: {re}')\n",
    "    # res_list.append(re)\n",
    "    # coefs_list.append(coef)\n",
    "    # corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    # coef=corr[0,1]\n",
    "    # print(f'coefficient void: {coef}')\n",
    "    # # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    # re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    # print(f're void: {re}')\n",
    "    # reg_list.append(re)\n",
    "    # coefg_list.append(coef)\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    # plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(-0.0, 0.05)\n",
    "    # plt.ylim(-0.0, 0.05)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    # plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    # plt.title('Predicted vs Actual Values')\n",
    "    # plt.xlabel('Actual Value')\n",
    "    # plt.ylabel('Predicted Value')\n",
    "    # plt.xlim(0, 0.4)\n",
    "    # plt.ylim(0, 0.4)\n",
    "    # plt.rcParams[\"font.size\"] = 20\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    corr=np.corrcoef(targ,pred)\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ-pred,2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ, pred, alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # target_layer = None\n",
    "    # if hasattr(model, 'conv3'):\n",
    "    #     target_layer = model.conv3\n",
    "    # elif hasattr(model, 'layer3'):\n",
    "    #     target_layer = model.layer3\n",
    "    # else:\n",
    "    #     for m in reversed(list(model.modules())):\n",
    "    #         if isinstance(m, torch.nn.Conv1d):\n",
    "    #             target_layer = m\n",
    "    #             break\n",
    "    # if target_layer is None:\n",
    "    #     raise RuntimeError(\"Could not find a suitable layer for Grad-CAM.\")\n",
    "\n",
    "    # gradcam_output_dir = os.path.join(odir, \"gradcam\")\n",
    "    # gradcam = GradCAM1d(model, target_layer)\n",
    "    # grad_cam_map = gradcam(xgradcam)\n",
    "    # gradcam.remove_hooks()\n",
    "\n",
    "    # plt.figure(figsize=(10,6))\n",
    "    # plt.rcParams['font.size'] = 20\n",
    "    # amp=10\n",
    "    # ta=np.arange(W)\n",
    "    # xgradcam=xgradcam.detach().cpu()\n",
    "    # xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    # plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    # plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    # grad_cam_map *= 30\n",
    "    # grad_cam_map -= amp\n",
    "    # plt.legend(loc='upper right')\n",
    "    # plt.plot(ta,grad_cam_map[:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, grad_cam_map[:],-amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.xlabel('Time Axis')\n",
    "    # plt.ylabel('Pressure [-]')\n",
    "    # plt.ylim(-amp,2*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # # plt.ylim(-amp,5*amp)\n",
    "    # # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.xlim(0,W)\n",
    "    # plt.grid(True)\n",
    "    # # plt.xlim(35,40)\n",
    "    # plt.tight_layout()\n",
    "    # new_save_path = os.path.join(odir, f\"gradcam{k}.png\")\n",
    "    # plt.savefig(new_save_path)\n",
    "    # plt.close()\n",
    "\n",
    "    # model.eval()\n",
    "    # model.zero_grad()\n",
    "\n",
    "    # # 1. \n",
    "    # xgradcam = xgradcam.to(device)\n",
    "\n",
    "    # # 2. ON\n",
    "    # xgradcam.requires_grad_()\n",
    "\n",
    "    # # 3. \n",
    "    # output = model(xgradcam)\n",
    "\n",
    "    # # 4. 1\n",
    "    # loss = output[0]\n",
    "    # loss.backward()\n",
    "\n",
    "    # # 5. .grad\n",
    "    # if xgradcam.grad is not None:\n",
    "    #     grads = xgradcam.grad.data #  [1, 5, 2500] \n",
    "        \n",
    "    #     # ---  ---\n",
    "    #     # abs()\n",
    "    #     salimap = grads.abs().squeeze(0)\n",
    "        \n",
    "    #     # 0~1 1e-8 \n",
    "    #     salimap = salimap / (salimap.max() + 1e-8)\n",
    "        \n",
    "    #     salimap = salimap.cpu().numpy()\n",
    "    #     salimap = salimap*10\n",
    "    #     print(salimap.shape)\n",
    "    # else:\n",
    "    #     print(\"requires_grad\")\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(10,6))\n",
    "    # plt.rcParams['font.size'] = 20\n",
    "    # amp=10\n",
    "    # xgradcam=xgradcam.detach().cpu()\n",
    "    # xgradcamplt=xgradcam.numpy().squeeze(0)\n",
    "    # plt.plot(ta, xgradcamplt[0,:], label='TDX1')\n",
    "    # plt.plot(ta, amp+xgradcamplt[1,:], label='TDX2')\n",
    "    # # plt.plot(ta, 2*amp+xgradcamplt[2,:], label='TDX3')\n",
    "    # # plt.plot(ta, 3*amp+xgradcamplt[3,:], label='TDX4')\n",
    "    # # plt.plot(ta, 4*amp+xgradcamplt[4,:], label='TDX5')\n",
    "    # plt.legend(loc='upper right')\n",
    "    # plt.plot(ta,salimap[0,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, salimap[0,:],0,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # plt.plot(ta,amp+salimap[1,:], color='red', label='Saliency-Map')\n",
    "    # plt.fill_between(ta, amp+salimap[1,:],amp,\n",
    "    #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,2*amp+salimap[2,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 2*amp+salimap[2,:],2*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,3*amp+salimap[3,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 3*amp+salimap[3,:],3*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # # plt.plot(ta,4*amp+salimap[4,:], color='red', label='Saliency-Map')\n",
    "    # # plt.fill_between(ta, 4*amp+salimap[4,:],4*amp,\n",
    "    # #         color='red',alpha=0.1)\n",
    "    # plt.xlabel('Time Axis')\n",
    "    # plt.ylabel('Pressure [-]')\n",
    "    # plt.ylim(-amp,2*amp)\n",
    "    # plt.yticks([-amp,0,amp,2*amp],[f\"{-amp}\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # # plt.ylim(-amp,5*amp)\n",
    "    # # plt.yticks([-amp,0,amp,2*amp,3*amp,4*amp,5*amp],[f\"{-amp}\",\"0\",\"0\",\"0\",\"0\",\"0\",f\"{amp}\"])\n",
    "    # plt.xlim(0,W)\n",
    "    # plt.grid(True)\n",
    "    # # plt.xlim(35,40)\n",
    "    # plt.tight_layout()\n",
    "    # new_save_path = os.path.join(odir, f\"saliency{k}.png\")\n",
    "    # plt.savefig(new_save_path)\n",
    "    # plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 2, 2500)\n",
      "(315, 5000)\n",
      "torch.Size([315, 5000])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m l1n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m l2n\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m loss\u001b[39m=\u001b[39mloss\u001b[39m+\u001b[39ml1\u001b[39m*\u001b[39ml1n\u001b[39m+\u001b[39ml2\u001b[39m*\u001b[39ml2n\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.42.21/home/user01/Document/yyamaguchi/documents/ml_airlift/ml_b4/main_ml.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l1' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os\n",
    "\n",
    "x_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/x_train_two_raw_std.npy\")\n",
    "t_train=np.load(\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset/t_train_two_raw_std.npy\")\n",
    "bdir=\"/mnt/sdb/yyamaguchi/simulationB4/bubble_glass_rand/dataset\"\n",
    "odir=os.path.join(bdir,\"outputs_2raw_std_nn\")\n",
    "wdir=os.path.join(odir,\"weights\")\n",
    "ldir=os.path.join(odir,\"logs\")\n",
    "device=\"cuda:0\"\n",
    "B=64\n",
    "W=2500\n",
    "lr=0.001\n",
    "N=100\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_length,4096)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096,2)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train=x_train.reshape(x_train.shape[0],-1)\n",
    "# x_train=x_train[:,[1,3,4],:]\n",
    "print(x_train.shape)\n",
    "x=torch.from_numpy(x_train).float()\n",
    "t=torch.from_numpy(t_train).float()\n",
    "# x=x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "amp=10\n",
    "res_list=[]\n",
    "coefs_list=[]\n",
    "reg_list=[]\n",
    "coefg_list=[]\n",
    "dataset=TensorDataset(x,t)\n",
    "Nttl=len(dataset)\n",
    "trasize=int(0.7*Nttl)\n",
    "valsize=int(0.15*Nttl)\n",
    "testsize=Nttl-trasize-valsize\n",
    "trainsetall,testset=random_split(dataset,[trasize+valsize,testsize])\n",
    "testloader=DataLoader(testset,batch_size=1,shuffle=False)\n",
    "\n",
    "for k in range(10):\n",
    "    trainset,valset=random_split(trainsetall,[trasize,valsize])\n",
    "    trainloader=DataLoader(trainset,batch_size=B,shuffle=True,drop_last=True)\n",
    "    valloader=DataLoader(valset,batch_size=B,shuffle=False)\n",
    "    model=SimpleNN(W*C).to(device)\n",
    "\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(params=model.parameters(),lr=lr)\n",
    "    tlosshistory=[]\n",
    "    vlosshistory=[]\n",
    "\n",
    "    for epoch in range(N):\n",
    "        model.train()\n",
    "        rloss=0.0\n",
    "        for bx, by in trainloader:\n",
    "            bx=bx.to(device)\n",
    "            by=by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o=model(bx)\n",
    "            loss=criterion(o,by)\n",
    "            l1n=sum(p.abs().sum() for p in model.parameters())\n",
    "            l2n=sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss=loss+l1*l1n+l2*l2n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rloss=rloss+loss.item()*bx.size(0)\n",
    "        eloss=rloss/len(trainloader.dataset)\n",
    "        tlosshistory.append(eloss)\n",
    "\n",
    "        model.eval()\n",
    "        vrloss=0.0\n",
    "        with torch.no_grad():\n",
    "            for vx,vy in valloader:\n",
    "                vx=vx.to(device)\n",
    "                vy=vy.to(device)\n",
    "                vo=model(vx)\n",
    "                vloss=criterion(vo,vy)\n",
    "                vrloss+=vloss.item()*vx.size(0)\n",
    "        veloss=vrloss/len(valloader.dataset)\n",
    "        vlosshistory.append(veloss)\n",
    "\n",
    "    os.makedirs(odir,exist_ok=True)\n",
    "    os.makedirs(wdir,exist_ok=True)\n",
    "    os.makedirs(ldir,exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(wdir,f'model{k}.pth'))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in tlosshistory], label='Train Log(Loss)')\n",
    "    plt.plot(range(1, N + 1), [np.log(l) for l in vlosshistory], label='Validation Log(Loss)')\n",
    "    plt.title('Learning Curve (Log Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log(Loss)')\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve_log{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, N + 1), tlosshistory, label='Train Loss')\n",
    "    plt.plot(range(1, N + 1), vlosshistory, label='Validation Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'learning_curve{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(wdir,f'model{k}.pth')))\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    targ=[]\n",
    "    with torch.no_grad():\n",
    "        for tx,ty in testloader:\n",
    "            tx=tx.to(device)\n",
    "            ty=ty.to(device)\n",
    "            o=model(tx)\n",
    "            pred.append(o.cpu())\n",
    "            targ.append(ty.cpu())\n",
    "    pred=torch.cat(pred,dim=0)\n",
    "    targ=torch.cat(targ,dim=0)\n",
    "\n",
    "    pred=pred.numpy()\n",
    "    targ=targ.numpy()\n",
    "\n",
    "    print(pred.shape)\n",
    "\n",
    "    corr=np.corrcoef(targ[:,0],pred[:,0])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient solid: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,0]-pred[:,0])/(targ[:,0]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,0]-pred[:,0],2))/targ.shape[0])\n",
    "    print(f're solid: {re}')\n",
    "    res_list.append(re)\n",
    "    coefs_list.append(coef)\n",
    "    corr=np.corrcoef(targ[:,1],pred[:,1])\n",
    "    coef=corr[0,1]\n",
    "    print(f'coefficient void: {coef}')\n",
    "    # re=np.mean(np.abs(targ[:,1]-pred[:,1])/(targ[:,1]+1e-7))\n",
    "    re=np.sqrt(np.sum(np.power(targ[:,1]-pred[:,1],2))/targ.shape[0])\n",
    "    print(f're void: {re}')\n",
    "    reg_list.append(re)\n",
    "    coefg_list.append(coef)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,0], pred[:,0], alpha=0.6, marker='o', label='Solid fraction')\n",
    "    plt.plot([-1, 1], [-1, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(-0.0, 0.05)\n",
    "    plt.ylim(-0.0, 0.05)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_solid{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(targ[:,1], pred[:,1], alpha=0.6, marker='o', label='Void fraction')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal (y=x)')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.xlabel('Actual Value')\n",
    "    plt.ylabel('Predicted Value')\n",
    "    plt.xlim(0, 0.4)\n",
    "    plt.ylim(0, 0.4)\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ldir, f'val_pred_vs_actual_void{k}.png'))\n",
    "    plt.close()\n",
    "\n",
    "res_list=np.array(res_list)\n",
    "coefs_list=np.array(coefs_list)\n",
    "reg_list=np.array(reg_list)\n",
    "coefg_list=np.array(coefg_list)\n",
    "print(f\"res_list:{res_list}\")\n",
    "print(f\"coefs_list:{coefs_list}\")\n",
    "print(f\"reg_list:{reg_list}\")\n",
    "print(f\"coefg_list:{coefg_list}\")\n",
    "print(f\"res:{np.mean(res_list)}\")\n",
    "print(f\"coefs:{np.mean(coefs_list)}\")\n",
    "print(f\"reg:{np.mean(reg_list)}\")\n",
    "print(f\"coefg:{np.mean(coefg_list)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
